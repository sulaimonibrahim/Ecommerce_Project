[core]
dags_folder = /opt/airflow/dags/etl_dag.py
logs_folder = /opt/airflow/logs
plugins_folder = /opt/airflow/plugins
executor = LocalExecutor
load_examples = False
fernet_key = yu3Q8UqlWYVvV-IM9i44EoOSaLhc1c3CrDhVe5VTIqE=

[database]
sql_alchemy_conn = postgresql+psycopg2://sulaimonibrahim:Ladi_555@postgres/ecommerce
sql_engine_encoding = utf-8

[webserver]
base_url = http://localhost:8080
web_server_host = 0.0.0.0
web_server_port = 8080
timeout = 300

[smtp]
smtp_host = localhost
smtp_starttls = True
smtp_ssl = False
smtp_user = airflow
smtp_password = airflow
smtp_port = 25
smtp_mail_from = airflow@example.com

[celery]
broker_url = redis://redis:6379/0
result_backend = db+postgresql://airflow:airflow@postgres/airflow

[scheduler]
job_heartbeat_sec = 5
scheduler_heartbeat_sec = 5
run_duration = -1
min_file_process_interval = 0
dag_dir_list_interval = 300
print_stats_interval = 30
scheduler_health_check_threshold = 30

[elasticsearch]
elasticsearch_host =
elasticsearch_log_id_template = {dag_id}-{task_id}-{execution_date}-{try_number}
elasticsearch_end_of_log_mark = end_of_log

[kubernetes]
dags_in_image = False
delete_worker_pods = True

[elasticsearch_configs]
use_ssl = False
verify_certs = True

[logging]
logging_level = INFO
fab_logging_level = WARN
logging_config_class = 

[metrics]
statsd_on = False
statsd_host = localhost
statsd_port = 8125
statsd_prefix = airflow

[secrets]
backend =
backend_kwargs =

[api]
auth_backend = airflow.api.auth.backend.deny_all

[lineage]
backend =

[atlas]
sasl_enabled = False
host =
port = 21000
username =
password =

[operators]
default_owner = airflow

[hive]
default_hive_mapred_queue =

[webserver_config]
authenticate = True
filter_by_owner = False
owner_mode = user

[kerberos]
ccache = /tmp/airflow_krb5_ccache
principal = airflow
reinit_frequency = 3600
kinit_path = kinit
keytab = airflow.keytab

[github_enterprise]
api_rev = v3

[admin]
hide_sensitive_variable_fields = True

[elasticsearch]
host =